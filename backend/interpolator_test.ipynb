{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FiveDReg Python Package\n",
    "\n",
    "This notebook demonstrates all examples from the official documentation.\n",
    "Workflow as a full package.\n",
    "\n",
    "**Ground Truth Function:**\n",
    "\n",
    "$$y = 2.0 \\cdot x_1 + (-1.5) \\cdot x_2^2 + 3.0 \\cdot \\sin(x_3) + 0.5 \\cdot x_4 \\cdot x_5$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [-1.9702132  2.0419214 -4.287335  -6.829669   3.5995965]\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import (\n",
    "    FiveDRegressor,\n",
    "    create_synthetic_dataset,\n",
    "    save_model,\n",
    "    load_model\n",
    ")\n",
    "\n",
    "# Create data\n",
    "X_train, y_train = create_synthetic_dataset(n_samples=1000, seed=42)\n",
    "X_test, y_test = create_synthetic_dataset(n_samples=200, seed=43)\n",
    "\n",
    "# Train model\n",
    "model = FiveDRegressor(hidden_layers=(64, 32, 16), max_epochs=50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save and load\n",
    "save_model(model, \"quickstart_model.pt\")\n",
    "loaded_model = load_model(\"quickstart_model.pt\")\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(f\"Predictions: {predictions[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 1: Create and Save Multiple Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train dataset: 3000 samples\n",
      "Saved val dataset: 600 samples\n",
      "Saved test dataset: 500 samples\n",
      "\n",
      "Available datasets:\n",
      "  - train_data.pkl\n",
      "  - val_data.pkl\n",
      "  - test_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import create_synthetic_dataset, save_dataset, list_datasets\n",
    "\n",
    "# Create train/val/test splits\n",
    "datasets = {\n",
    "    'train': create_synthetic_dataset(n_samples=3000, seed=42),\n",
    "    'val': create_synthetic_dataset(n_samples=600, seed=43),\n",
    "    'test': create_synthetic_dataset(n_samples=500, seed=44)\n",
    "}\n",
    "\n",
    "# Save all datasets\n",
    "for name, (X, y) in datasets.items():\n",
    "    save_dataset(X, y, f\"{name}_data.pkl\")\n",
    "    print(f\"Saved {name} dataset: {X.shape[0]} samples\")\n",
    "\n",
    "# List all datasets\n",
    "print(\"\\nAvailable datasets:\")\n",
    "for dataset in list_datasets():\n",
    "    print(f\"  - {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset: 3600 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fivedreg import load_dataset, save_dataset\n",
    "\n",
    "# Load multiple datasets\n",
    "X1, y1 = load_dataset(\"train_data.pkl\")\n",
    "X2, y2 = load_dataset(\"val_data.pkl\")\n",
    "\n",
    "# Merge datasets\n",
    "X_merged = np.vstack([X1, X2])\n",
    "y_merged = np.concatenate([y1, y2])\n",
    "\n",
    "# Save merged dataset\n",
    "save_dataset(X_merged, y_merged, \"merged_data.pkl\")\n",
    "print(f\"Merged dataset: {X_merged.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Add Custom Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with noise level=0.1\n",
      "Created dataset with noise level=0.5\n",
      "Created dataset with noise level=1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fivedreg import create_synthetic_dataset, save_dataset\n",
    "\n",
    "# Create clean dataset\n",
    "X, y_clean = create_synthetic_dataset(n_samples=1000, seed=42)\n",
    "\n",
    "# Add different noise levels manually\n",
    "noise_levels = [0.1, 0.5, 1.0]\n",
    "\n",
    "for sigma in noise_levels:\n",
    "    # Add Gaussian noise manually\n",
    "    rng = np.random.default_rng(0)\n",
    "    noise = rng.normal(0, sigma, size=y_clean.shape)\n",
    "    y_noisy = y_clean + noise\n",
    "    \n",
    "    # Save noisy dataset\n",
    "    filename = f\"noisy_data_{sigma:.1f}.pkl\"\n",
    "    save_dataset(X, y_noisy, filename)\n",
    "    print(f\"Created dataset with noise level={sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 4: Basic Training with Progress Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: train_mse=12.984546 val_mse=7.072946 train_r2=0.0085 val_r2=0.3723\n",
      "Epoch   20: train_mse=0.184240 val_mse=0.201838 train_r2=0.9859 val_r2=0.9821\n",
      "Epoch   40: train_mse=0.072423 val_mse=0.079293 train_r2=0.9945 val_r2=0.9930\n",
      "Epoch   60: train_mse=0.031439 val_mse=0.043103 train_r2=0.9976 val_r2=0.9962\n",
      "Epoch   80: train_mse=0.027356 val_mse=0.028424 train_r2=0.9979 val_r2=0.9975\n",
      "Epoch  100: train_mse=0.015373 val_mse=0.021336 train_r2=0.9988 val_r2=0.9981\n",
      "\n",
      "Final training loss: 0.015373\n",
      "Final validation loss: 0.021336\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import FiveDRegressor, create_synthetic_dataset\n",
    "\n",
    "# Create datasets\n",
    "X_train, y_train = create_synthetic_dataset(n_samples=2000, seed=42)\n",
    "X_val, y_val = create_synthetic_dataset(n_samples=400, seed=43)\n",
    "\n",
    "# Train with verbose output\n",
    "model = FiveDRegressor(\n",
    "    hidden_layers=(64, 32, 16),\n",
    "    max_epochs=100,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=True  # Shows progress during training\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Access training history\n",
    "print(f\"\\nFinal training loss: {model.history['train_loss'][-1]:.6f}\")\n",
    "print(f\"Final validation loss: {model.history['val_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Training with Patience-Based Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: train_mse=14.736540 val_mse=11.505248 train_r2=-0.1253 val_r2=-0.0211\n",
      "Epoch   20: train_mse=0.521205 val_mse=0.482787 train_r2=0.9602 val_r2=0.9572\n",
      "Epoch   40: train_mse=0.135748 val_mse=0.168969 train_r2=0.9896 val_r2=0.9850\n",
      "Epoch   60: train_mse=0.051124 val_mse=0.067393 train_r2=0.9961 val_r2=0.9940\n",
      "Epoch   80: train_mse=0.030811 val_mse=0.043782 train_r2=0.9976 val_r2=0.9961\n",
      "Epoch  100: train_mse=0.020390 val_mse=0.032992 train_r2=0.9984 val_r2=0.9971\n",
      "Epoch  120: train_mse=0.014892 val_mse=0.030595 train_r2=0.9989 val_r2=0.9973\n",
      "Epoch  140: train_mse=0.012812 val_mse=0.025517 train_r2=0.9990 val_r2=0.9977\n",
      "Epoch  160: train_mse=0.009720 val_mse=0.024149 train_r2=0.9993 val_r2=0.9979\n",
      "Epoch  180: train_mse=0.008486 val_mse=0.022015 train_r2=0.9994 val_r2=0.9980\n",
      "Epoch  200: train_mse=0.006704 val_mse=0.020565 train_r2=0.9995 val_r2=0.9982\n",
      "Epoch  220: train_mse=0.006399 val_mse=0.020123 train_r2=0.9995 val_r2=0.9982\n",
      "Epoch  240: train_mse=0.005763 val_mse=0.020197 train_r2=0.9996 val_r2=0.9982\n",
      "Epoch  260: train_mse=0.005060 val_mse=0.018295 train_r2=0.9996 val_r2=0.9984\n",
      "Epoch  280: train_mse=0.004651 val_mse=0.018696 train_r2=0.9996 val_r2=0.9983\n",
      "Epoch  300: train_mse=0.003997 val_mse=0.016816 train_r2=0.9997 val_r2=0.9985\n",
      "Epoch  320: train_mse=0.003544 val_mse=0.016637 train_r2=0.9997 val_r2=0.9985\n",
      "Epoch  340: train_mse=0.004744 val_mse=0.017520 train_r2=0.9996 val_r2=0.9984\n",
      "Epoch  360: train_mse=0.005177 val_mse=0.018916 train_r2=0.9996 val_r2=0.9983\n",
      "Epoch  380: train_mse=0.002748 val_mse=0.016536 train_r2=0.9998 val_r2=0.9985\n",
      "Early stopping at epoch 388\n",
      "Training stopped at epoch 388\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import FiveDRegressor, create_synthetic_dataset\n",
    "\n",
    "X_train, y_train = create_synthetic_dataset(n_samples=2000, seed=42)\n",
    "X_val, y_val = create_synthetic_dataset(n_samples=400, seed=43)\n",
    "\n",
    "# Train with patience-based early stopping\n",
    "# Early stopping is triggered automatically when validation data is provided\n",
    "# and no improvement occurs for 'patience' epochs\n",
    "model = FiveDRegressor(\n",
    "    hidden_layers=(128, 64, 32),\n",
    "    max_epochs=500,  # High max_epochs\n",
    "    patience=30,  # Stop if no improvement for 30 epochs\n",
    "    min_delta=1e-6,  # Minimum change to qualify as improvement\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Providing validation data enables early stopping behavior\n",
    "model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Check if early stopping occurred\n",
    "epochs_trained = len(model.history['epoch'])\n",
    "print(f\"Training stopped at epoch {epochs_trained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Hyperparameter Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing architecture: (32, 16)\n",
      "  R² score: 0.966261\n",
      "\n",
      "Testing architecture: (64, 32, 16)\n",
      "  R² score: 0.989771\n",
      "\n",
      "Testing architecture: (128, 64, 32, 16)\n",
      "  R² score: 0.996946\n",
      "\n",
      "Best architecture: (128, 64, 32, 16) (R² = 0.996946)\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import FiveDRegressor, create_synthetic_dataset\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Create datasets\n",
    "X_train, y_train = create_synthetic_dataset(n_samples=2000, seed=42)\n",
    "X_val, y_val = create_synthetic_dataset(n_samples=400, seed=43)\n",
    "X_test, y_test = create_synthetic_dataset(n_samples=500, seed=44)\n",
    "\n",
    "# Test different architectures\n",
    "architectures = [\n",
    "    (32, 16),\n",
    "    (64, 32, 16),\n",
    "    (128, 64, 32, 16)\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"\\nTesting architecture: {arch}\")\n",
    "    \n",
    "    model = FiveDRegressor(\n",
    "        hidden_layers=arch,\n",
    "        max_epochs=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[arch] = r2\n",
    "    print(f\"  R² score: {r2:.6f}\")\n",
    "\n",
    "# Find best architecture\n",
    "best_arch = max(results, key=results.get)\n",
    "print(f\"\\nBest architecture: {best_arch} (R² = {results[best_arch]:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Training with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: train_mse=14.736452 val_mse=11.505078 train_r2=-0.1253 val_r2=-0.0211\n",
      "Epoch   20: train_mse=0.526133 val_mse=0.482770 train_r2=0.9598 val_r2=0.9572\n",
      "Epoch   40: train_mse=0.151865 val_mse=0.178982 train_r2=0.9884 val_r2=0.9841\n",
      "Epoch   60: train_mse=0.059693 val_mse=0.083397 train_r2=0.9954 val_r2=0.9926\n",
      "Epoch   80: train_mse=0.036484 val_mse=0.055408 train_r2=0.9972 val_r2=0.9951\n",
      "Epoch  100: train_mse=0.022975 val_mse=0.038103 train_r2=0.9982 val_r2=0.9966\n",
      "Epoch  120: train_mse=0.017541 val_mse=0.033812 train_r2=0.9987 val_r2=0.9970\n",
      "Epoch  140: train_mse=0.014743 val_mse=0.026533 train_r2=0.9989 val_r2=0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FiveDRegressor(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (train_mse_metric): MeanSquaredError()\n",
       "  (val_mse_metric): MeanSquaredError()\n",
       "  (train_r2_metric): R2Score()\n",
       "  (val_r2_metric): R2Score()\n",
       "  (train_mae_metric): MeanAbsoluteError()\n",
       "  (val_mae_metric): MeanAbsoluteError()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fivedreg import FiveDRegressor, create_synthetic_dataset\n",
    "\n",
    "X_train, y_train = create_synthetic_dataset(n_samples=2000, seed=42)\n",
    "X_val, y_val = create_synthetic_dataset(n_samples=400, seed=43)\n",
    "\n",
    "# Train with weight decay (L2 regularization)\n",
    "model = FiveDRegressor(\n",
    "    hidden_layers=(128, 64, 32),\n",
    "    max_epochs=150,\n",
    "    weight_decay=1e-4,  # L2 regularization\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 8: Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 10000 predictions\n",
      "Predictions range: [-18.55, 7.25]\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import FiveDRegressor, create_synthetic_dataset, load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"quickstart_model.pt\")\n",
    "\n",
    "# Create large test set\n",
    "X_test, y_test = create_synthetic_dataset(n_samples=10000, seed=99)\n",
    "\n",
    "# Make predictions (automatically batched)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Made {len(y_pred)} predictions\")\n",
    "print(f\"Predictions range: [{y_pred.min():.2f}, {y_pred.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9: Single Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [1. 2. 3. 4. 5.]\n",
      "Prediction: 6.0079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fivedreg import load_model\n",
    "\n",
    "# Load model\n",
    "model = load_model(\"quickstart_model.pt\")\n",
    "\n",
    "# Single sample (must be 2D)\n",
    "x_single = np.array([[1.0, 2.0, 3.0, 4.0, 5.0]], dtype=np.float32)\n",
    "y_pred = model.predict(x_single)\n",
    "\n",
    "print(f\"Input: {x_single[0]}\")\n",
    "print(f\"Prediction: {y_pred[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 10: Custom Input Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: pred=2.6421, truth=2.0000, error=0.6421\n",
      "Sample 2: pred=-2.3894, truth=-1.5000, error=0.8894\n",
      "Sample 3: pred=2.3321, truth=2.5244, error=0.1923\n",
      "Sample 4: pred=1.2126, truth=0.5000, error=0.7126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fivedreg import load_model, ground_truth_function\n",
    "\n",
    "# Load model\n",
    "model = load_model(\"quickstart_model.pt\")\n",
    "\n",
    "# Create custom inputs\n",
    "custom_inputs = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],  # Only x1 = 1\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],  # Only x2 = 1\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0],  # Only x3 = 1\n",
    "    [0.0, 0.0, 0.0, 1.0, 1.0],  # Only x4, x5 = 1\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(custom_inputs)\n",
    "ground_truth = ground_truth_function(custom_inputs)\n",
    "\n",
    "# Compare\n",
    "for i, (pred, truth) in enumerate(zip(predictions, ground_truth)):\n",
    "    error = abs(pred - truth)\n",
    "    print(f\"Sample {i+1}: pred={pred:.4f}, truth={truth:.4f}, error={error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 11: Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "  R² Score:      0.939575\n",
      "  MSE:           0.799277\n",
      "  RMSE:          0.894023\n",
      "  MAE:           0.612074\n",
      "  MAPE:          113.74%\n",
      "  Max Error:     6.974006\n"
     ]
    }
   ],
   "source": [
    "from fivedreg import load_model, create_synthetic_dataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load model and create test data\n",
    "model = load_model(\"quickstart_model.pt\")\n",
    "X_test, y_test = create_synthetic_dataset(n_samples=1000, seed=99)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate percentage errors\n",
    "eps = 1e-12\n",
    "mape = np.mean(np.abs((y_test - y_pred) / (np.abs(y_test) + eps))) * 100\n",
    "max_error = np.max(np.abs(y_test - y_pred))\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"  R² Score:      {r2:.6f}\")\n",
    "print(f\"  MSE:           {mse:.6f}\")\n",
    "print(f\"  RMSE:          {rmse:.6f}\")\n",
    "print(f\"  MAE:           {mae:.6f}\")\n",
    "print(f\"  MAPE:          {mape:.2f}%\")\n",
    "print(f\"  Max Error:     {max_error:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
